# -*- coding: utf-8 -*-
"""Assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VJradbbjrk2Y5btHP0wNXP3wFRAZZhre
"""

#Filter Function will return user data after removing the duplicates in last five minutes 
def filter_user(final_user_list,user_dict):
    if((len(final_user_list)<1)and len(user_dict)<1):
        return final_user_list
    else:
        for i in user_dict:
            for j in final_user_list:
                if(j.get(i)!=None):
                    if(j.get(i)>user_dict.get(i)):
                        user_dict[i]=j.get(i)
                    j.pop(i)
        return final_user_list

#This function will print the values and returns the list of dictinary holding the user data of last five minutes 
def User_report(user_dict,user_list):
    temp={}
    #to check the 
    user_list=filter_user(user_list,user_dict)
    if(len(user_list)<5):
        user_list.append(user_dict)
    else:
        user_list.pop(0)
        user_list.append(user_dict)
    for i in user_list:
        for j in i:
            temp[j]=i.get(j)
    print("Users who made changes to en.wikipedia.org")
    s_list=sorted(temp.items(), key=lambda x: x[1], reverse=True)
    try:  
        for i in s_list:
            print("{}: {} ".format(i[0],i[1]),end="\n")
    except AttributeError:
        print("Empty List")
    print("\n")
    return user_list

#Filter Function will return domain data after removing the duplicates in last five minutes 
import copy
def domain_filter(final_domain_list,domain_dict):
    #creating the copy of dictinary 
    temp_domain_dict=copy.deepcopy(domain_dict) 
    # to check if the len is lees than 1
    if((len(final_domain_list)<1)and len(domain_dict)<1):
        return final_domain_list
    else:
        #if not then taking the union if two same domain occured
        for i in temp_domain_dict:
            for j in final_domain_list:
                if(j.get(i)!=None):
                    x=j.get(i)
                    y=temp_domain_dict.get(i)
                    j[i]=x.union(y)
                    domain_dict.pop(i)
        return final_domain_list

#This fucntion ensures that count of unique page tittles and print the domain report 
def domain_report1(domain_dict,domain_list):
    domain_list=domain_filter(domain_list,domain_dict)
    temp={}
    #to check if the data is having less than 5 minutes 
    if(len(domain_list)<5):
        #print(templist,"list")
        domain_list.append(domain_dict)
    else:
        # if not then popping the first minute data 
        domain_list.pop(0)
        #print(templist,"list")
        domain_list.append(domain_dict)
        # counting the unique tittles
    for i in domain_list:
        for j in i:
            temp[j]=len(i[j])
    #sorting the values 
    sorted_list=sorted(temp.items(), key=lambda x: x[1], reverse=True)
    #printing the values 
    print("Total number of Wikipedia Domains Updated: {} \n \n".format(len(sorted_list)))
    for i in sorted_list:
        print("{}: {} pages updated".format(i[0],i[1]))
    print("\n \n")
    return domain_list

# This will create the list of page tittle for each minute 
def Validate_Domain(change,temp):
    # Assign the set variable to have the unique page tittle 
    test_list=set()
    #check for the vlaue none 
    if(change.get("page_title")!=None):
        #to check if we have exist domain
            if(temp.get(change.get('meta').get("domain"))==None):
                test_list.add(change.get("page_title"))
                temp[change.get('meta').get("domain")]=test_list
            else:
                #if not then creating the domain and assigning the value 
                test_list=temp[change.get('meta').get("domain")]
                test_list.add(change.get("page_title"))
                temp[change.get('meta').get("domain")]=test_list
    return temp

#This will filter all the domains for en.wikipedia.org and user is not bot and create the list for one minute 
def Validate_user(temp,change):
    #Check for the condition if value is none 
    if(temp.get(change.get('performer').get("user_text"))==None and change.get('performer').get("user_text")!= None):
        try:
            #check for the domain en.en.wikipedia.org and the user is not bot
            if(change.get('meta').get("domain")=="en.wikipedia.org" and change.get('performer').get("user_is_bot")!=True):
                #if edit count is none then assigning value 0
                if(change.get('performer').get("user_edit_count")==None):
                    temp[change.get('performer').get("user_text")]=0
                else:
                    #if not then assigning the edit count
                    temp[change.get('performer').get("user_text")]=change.get('performer').get("user_edit_count")
        except AttributeError:
            temp[change.get('performer').get("user_text")]=0
    return temp

# This function will load the json, create the process to run parallely and generate the report of each domain and user 
import json
import time
from sseclient import SSEClient as EventSource
import multiprocessing as mp
def export_data(url):
    # manager dictonary will have the user data for 60 min which is being validated
    validate_dict=mp.Manager().dict()
    # dictionary of the json
    change={}
    # manager dictonary will have the domain data for 60 min which is being validated
    temp=mp.Manager().dict()
    #list containing the domain data of last 5 minutes with the count of unique values
    final_temp=list()
    # Declare to track the time for 60 seconds
    current=time.time()
    final_list=list()#list containing the user data of last 5 minutes 
    for event in EventSource(url):
        if event.event == 'message':
            try:
                change = json.loads(event.data)
            except ValueError: 
                pass
            if(len(change)!=0):
                #Created the process to call Validate_user
                p1=mp.Process(target=Validate_user(validate_dict,change))
                #The process has started 
                p1.start()
                #The process has terminated 
                p1.terminate()
                #Created the process to call Validate_domain
                p2=mp.Process(target=Validate_Domain(change,temp))
                #The Process has started 
                p2.start()
                #The process has terminate 
                p2.terminate()
                #sleep to get process terminated 
                time.sleep(0.2)
                # check for the time of 60 seconds 
                if(current+60<=time.time()):
                    final_list=User_report(validate_dict,final_list)
                    final_temp=domain_report1(temp,final_temp)
                    #Cleared the one minute data after storing 
                    validate_dict={}
                    temp={}
                    #assign the current time to iterate for the next 60 minutes
                    current=time.time()

if __name__ == "__main__":
    #Calling the function to call the url
    try:
        export_data('https://stream.wikimedia.org/v2/stream/revision-create')
    except KeyboardInterrupt:
        print("Program Terminated")
